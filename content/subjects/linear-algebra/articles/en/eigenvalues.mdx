---
title:
  ru: "Собственные значения и собственные векторы"
  en: "Eigenvalues & Eigenvectors"
  cz: "Vlastní čísla a vlastní vektory"
slug: "eigenvalues"
author: "ivan-petrov"
keywords:
  ru: ["собственные значения", "собственные вектора", "диагонализация"]
  en: ["eigenvalues", "eigenvectors", "diagonalization"]
  cz: ["vlastní čísla", "vlastní vektory", "diagonalizace"]
created: "2024-10-01"
updated: "2025-02-01"
difficulty: "advanced"
estimatedReadTime: 15
prerequisites: ["vectors-intro", "matrix-operations"]
---

# Eigenvalues & Eigenvectors

An eigenvector of a square matrix A is a nonzero vector **v** such that multiplication by A only changes its scale: A**v** = λ**v**. The scalar λ is the corresponding eigenvalue.

## Finding Eigenvalues

To find eigenvalues, solve the characteristic equation: det(A - λI) = 0.

```python
import numpy as np

A = np.array([[4, 2], [1, 3]])
eigenvalues, eigenvectors = np.linalg.eig(A)
print(f"Eigenvalues: {eigenvalues}")
print(f"Eigenvectors:\n{eigenvectors}")
```

## Diagonalization

A matrix A is diagonalizable if it can be written as A = PDP⁻¹, where D is a diagonal matrix of eigenvalues and P is the matrix of eigenvectors. This decomposition makes computing matrix powers trivial: Aⁿ = PDⁿP⁻¹.

## Applications

Eigenvalues appear everywhere in applied mathematics:

1. **Principal Component Analysis (PCA)**: Data dimensionality reduction
2. **Google PageRank**: Dominant eigenvector of the web graph
3. **Quantum Mechanics**: Observable measurements are eigenvalues
4. **Vibration Analysis**: Natural frequencies of mechanical systems
